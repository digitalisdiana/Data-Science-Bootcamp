{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging et Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour atteindre des performances optimales, les scientifiques des données se tournent souvent vers une technique appelée assemblage de modèles , dans laquelle plusieurs algorithmes sont combinés de manière intelligente pour obtenir de meilleurs résultats. Les exemples courants incluent Random Forest ( Bagging ) et Gradient Boosted Decision Trees ( Boosting ), mais nous pouvons également utiliser l'apprentissage d'ensemble avec des modèles arbitraires. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, vous apprendrez comment utiliser Python Sklearn BaggingClassifier pour ajuster le modèle à l'aide de l'algorithme Bagging. Ce qui suit est fait pour illustrer comment Bagging Classifier aide à améliorer les performances de généralisation du modèle. Afin de démontrer les aspects de la performance de généralisation, les opérations suivantes sont effectuées:\n",
    "\n",
    "*     Un modèle est ajusté à l'aide de l'algorithme LogisticRegression\n",
    "*     Un modèle est ajusté en utilisant BaggingClassifier avec l'estimateur de base comme LogisticRegression\n",
    "\n",
    "Le jeu de données Sklearn sur le cancer du sein est utilisé pour ajuster le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrainement d'un modèle en utilsant la Regression Logistique**\n",
    "\n",
    "Nous allons faire des prediction sur le cancer du sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "bc_data = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split en features et targets\n",
    "X = bc_data.data\n",
    "y = bc_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test split\n",
    "train_X, test_X, train_y, test_y  = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Estimator\n",
    "pipeline = make_pipeline(StandardScaler(),LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "pipeline.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model scores on test and training data\n",
    "pipeline.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912087912087912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle propose les scores suivants. Notez que le modèle a tendance à sur-ajuster les données car le score du test est de 0,991et le score d'entraînement est de 0,991."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustement du modèle à l'aide du classificateur bagging\n",
    "\n",
    "<!--Dans cette section, nous ajusterons un classificateur baggin en utilisant différents hyperparamètres tels que le suivant et l'estimateur de base en tant que pipeline construit à l'aide de la régression logistique. Notez que vous pouvez effectuer une recherche de grille ou une recherche aléatoire pour obtenir l'estimateur le plus approprié.-->\n",
    "Hyperparametres:\n",
    "\n",
    "*     n_estimateurs = 100\n",
    "*     max_features = 10\n",
    "*     max_samples = 100\n",
    "\n",
    "Voici à quoi ressemblera le code Python pour le modèle Bagging Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Estimator\n",
    "pipeline_2 = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the bagging classifier\n",
    "bgc = BaggingClassifier(base_estimator = pipeline_2, n_estimators = 100, max_features = 10, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=Pipeline(steps=[('standardscaler',\n",
       "                                                  StandardScaler()),\n",
       "                                                 ('logisticregression',\n",
       "                                                  LogisticRegression())]),\n",
       "                  max_features=10, n_estimators=100, n_jobs=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the bagging classifier\n",
    "bgc.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model scores on test and training data\n",
    "bgc.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846153846153847"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgc.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle propose les scores suivants. Notez que le modèle a tendance à surajouter les données car le score au test est de 0,958 et le score d'entraînement est de 0,972. Cependant, le modèle donnera de meilleures performances de généralisation que l'ajustement du modèle avec la régression logistique.<br>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous examinerons les codes Python pour entraîner un modèle à l'aide de GradientBoostingRegressor pour prédire le prix du logement à Boston Houses.\n",
    "\n",
    "<!--*     Entraîner le modèle de régression par amplification de gradient\n",
    "*     Déterminer l'importance de la fonctionnalité\n",
    "*     Évaluer la formation et tester la déviance (perte)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code Python pour entraîner le modèle à l'aide du jeu de données Boston et de l'algorithme Gradient Boosting Regressor. Notez certains des éléments suivants dans le code ci-dessous:\n",
    "\n",
    "*    L'ensemble de données Sklearn Boston est utilisé pour la formation\n",
    "*    L'implémentation Sklearn GradientBoostingRegressor est utilisée pour ajuster le modèle.\n",
    "*    Le modèle de régression avec amplification de gradient crée une forêt de 1000 arbres avec une profondeur maximale de 3 et une perte de carré moindre.\n",
    "*    Les hyperparamètres utilisés pour entraîner les modèles sont les suivants:\n",
    "     *   n_estimators: nombre d'arbres utilisés pour booster\n",
    "     *   max_depth: Profondeur maximale de l'arbre\n",
    "     *   learning_rate: Taux selon lequel le résultat de chaque arbre sera mis à l'échelle ou réduit\n",
    "     *   perte: fonction de perte à optimiser. Les options pour les fonctions de perte sont: ls, lad, huber, quantile. ls représente la moindre perte carrée. lad représente la moindre déviation absolue. huber représente la combinaison des deux, ls et lad.\n",
    "*    Coefficient de détermination, R-carré est utilisé pour mesurer la précision du modèle. Le score de la méthode invoqué sur l'instance de la régression d'amplification de gradient entraînerait l'impression du R-carré\n",
    "*    Vous pouvez également calculer l'erreur quadratique moyenne (MSE) pour mesurer les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston Dataset\n",
    "house_data = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = house_data.data\n",
    "y_2 = house_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Test Split\n",
    "train_X_2, test_X_2, train_y_2, test_y_2  = train_test_split(X_2, y_2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "sds = StandardScaler()\n",
    "train_X_sds = sds.fit_transform(train_X_2)\n",
    "test_X_sds = sds.fit_transform(test_X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for GradientBoostingRegressor \n",
    "hparams = {'n_estimators':100,'min_samples_split':5,'learning_rate':0.01, 'loss':'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of gradient boosting regressor \n",
    "gbr = GradientBoostingRegressor(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, min_samples_split=5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "gbr.fit(train_X_sds,train_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7364466891620205"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Coefficient of determination R^2\n",
    "gbr.score(test_X_sds,test_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.50343850436667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the mean squared error\n",
    "mse = mean_squared_error(test_y_2, gbr.predict(test_X_sds))\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision du modèle peut être mesurée en termes de coefficient de détermination, R2 (R-carré) ou erreur quadratique moyenne (MSE). La valeur du modèle R2 s'est avérée 0,918 et la valeur MSE s'est avérée être 5,9486."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
